{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7112bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/c/cyrusyc/.conda/envs/dev/lib/python3.11/site-packages/mp_api/client/mprester.py:182: UserWarning: mpcontribs-client not installed. Install the package to query MPContribs data, or construct pourbaix diagrams: 'pip install mpcontribs-client'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPLLM is ready to serve you!\n",
      "Conversation started.\n",
      "{\n",
      "  \"id\": \"chatcmpl-80hzEzhIPCFbdW8J9faDWzfNWgRjS\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179776,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Calling Materials Project API...\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 142,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 147\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"chatcmpl-80hzF8nHF0DqTqay9F457ac9yoFD0\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179777,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"search_materials_magnetism__get\",\n",
      "          \"arguments\": \"{\\n  \\\"formula\\\": \\\"YbCl3\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 16190,\n",
      "    \"completion_tokens\": 24,\n",
      "    \"total_tokens\": 16214\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06daf7d93a5e4419b2f1f2f5cd87bb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving MaterialsDoc documents:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d10b3f8fcd4428a4c8266c881a843f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving MagnetismDoc documents:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-80hzLRFemHPlmfL2lCdx3BdAdcHog\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179783,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"YbCl3 can exist in both magnetic and non-magnetic forms. There are two magnetic configurations of YbCl3, with the material IDs mp-1025400 and mp-1187659, which exhibit ferromagnetic ordering. These configurations have a total magnetization of approximately 2.0 and 2.0, respectively. On the other hand, there is a non-magnetic configuration of YbCl3 with the material ID mp-1025388. This non-magnetic configuration has a total magnetization of approximately 0.0.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 581,\n",
      "    \"completion_tokens\": 114,\n",
      "    \"total_tokens\": 695\n",
      "  }\n",
      "}\n",
      "YbCl3 can exist in both magnetic and non-magnetic forms. There are two magnetic configurations of YbCl3, with the material IDs mp-1025400 and mp-1187659, which exhibit ferromagnetic ordering. These configurations have a total magnetization of approximately 2.0 and 2.0, respectively. On the other hand, there is a non-magnetic configuration of YbCl3 with the material ID mp-1025388. This non-magnetic configuration has a total magnetization of approximately 0.0.\n",
      "{\n",
      "  \"id\": \"chatcmpl-80hznGERaQ91QmGd0MSe7aq3jE0Hz\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179811,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Calling Materials Project API...\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 287,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 292\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"chatcmpl-80hzoJY1FPMZTXybXdWqEuoWzNOKb\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179812,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"search_materials_summary__get\",\n",
      "          \"arguments\": \"{\\n  \\\"material_ids\\\": \\\"mp-1025400,mp-1187659\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 16332,\n",
      "    \"completion_tokens\": 30,\n",
      "    \"total_tokens\": 16362\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a2dfdc921a44ada78f54ea9c7a21cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-80hzrtw1Rz3SzMQCPaRkXtzsXdZ6l\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179815,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The magnetic configurations of YbCl3, with the material IDs mp-1025400 and mp-1187659, exhibit ferromagnetic ordering. These configurations have a total magnetization of approximately 2.0 and 2.0, respectively. Ferromagnetic materials have a spontaneous magnetization even in the absence of an external magnetic field. YbCl3 in these magnetic configurations shows magnetic properties that can be useful in various applications such as magnetic storage, sensors, and spintronics.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 252,\n",
      "    \"completion_tokens\": 101,\n",
      "    \"total_tokens\": 353\n",
      "  }\n",
      "}\n",
      "The magnetic configurations of YbCl3, with the material IDs mp-1025400 and mp-1187659, exhibit ferromagnetic ordering. These configurations have a total magnetization of approximately 2.0 and 2.0, respectively. Ferromagnetic materials have a spontaneous magnetization even in the absence of an external magnetic field. YbCl3 in these magnetic configurations shows magnetic properties that can be useful in various applications such as magnetic storage, sensors, and spintronics.\n",
      "{\n",
      "  \"id\": \"chatcmpl-80i0cNncZIVlgFiWoZau7obZksfqH\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179862,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Spintronics, short for spin electronics, is a field of study that focuses on utilizing the spin of electrons as a fundamental property for information storage, processing, and communication. Unlike traditional electronics that rely on the charge of electrons, spintronics utilizes both the charge and spin of electrons to encode and manipulate information. This field aims to develop devices and technologies that are more energy-efficient, faster, and have higher storage capacities compared to conventional electronic devices. Spintronics has the potential to revolutionize various areas such as computing, data storage, and sensor technology.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 414,\n",
      "    \"completion_tokens\": 112,\n",
      "    \"total_tokens\": 526\n",
      "  }\n",
      "}\n",
      "Spintronics, short for spin electronics, is a field of study that focuses on utilizing the spin of electrons as a fundamental property for information storage, processing, and communication. Unlike traditional electronics that rely on the charge of electrons, spintronics utilizes both the charge and spin of electrons to encode and manipulate information. This field aims to develop devices and technologies that are more energy-efficient, faster, and have higher storage capacities compared to conventional electronic devices. Spintronics has the potential to revolutionize various areas such as computing, data storage, and sensor technology.\n",
      "{\n",
      "  \"id\": \"chatcmpl-80i1jJvXYoMJMsDPE2Szk9y3HFZxJ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695179931,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Calling Materials Project API...\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 552,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 557\n",
      "  }\n",
      "}\n",
      "Error: This model's maximum context length is 16385 tokens. However, your messages resulted in 16607 tokens (524 in the messages, 16083 in the functions). Please reduce the length of the messages or functions. Trying again with gpt-4-32k.\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `gpt-4-32k` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/pscratch/sd/c/cyrusyc/materiathena/materiathena/mp/agent.py:441\u001b[0m, in \u001b[0;36mMPLLM.material_response\u001b[0;34m(self, message, model)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    442\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    443\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m    444\u001b[0m         functions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaterial_functions,\n\u001b[1;32m    445\u001b[0m         function_call\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    446\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    447\u001b[0m         top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    448\u001b[0m     )\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m )\n\u001b[0;32m--> 298\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 16385 tokens. However, your messages resulted in 16607 tokens (524 in the messages, 16083 in the functions). Please reduce the length of the messages or functions.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mIs YbCl3 magnetic or non-magnetic?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# user_input = \"What is the energy above hull of Cu3P4Pb3O16 at 0K?\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# user_input = \"Is Cu stable in FCC or BCC structure at 0K based on the energy distance above hull?\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# user_input = \"Do we have stable Cu-substituted lead phosphate apatite at 0K?\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# user_input = \"What is the bandgap of the most stable magnetite?\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# user_input = \"Search for the necessary information for FCC Cu and summarize for me.\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m mpllm\u001b[39m.\u001b[39;49mrun_material_conversation(user_input\u001b[39m=\u001b[39;49muser_input, debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/pscratch/sd/c/cyrusyc/materiathena/lab/mp.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# mpllm.run_material_conversation(user_input, model=\"gpt-3.5-turbo-16k-0613\", debug=True)\u001b[39;00m\n",
      "File \u001b[0;32m/pscratch/sd/c/cyrusyc/materiathena/materiathena/mp/agent.py:482\u001b[0m, in \u001b[0;36mMPLLM.run_material_conversation\u001b[0;34m(self, user_input, model, debug)\u001b[0m\n\u001b[1;32m    479\u001b[0m gen_reponse_msg \u001b[39m=\u001b[39m gen_reponse[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m gen_reponse_msg[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCalling Materials Project API...\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 482\u001b[0m     mat_reponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaterial_response(\n\u001b[1;32m    483\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_input},\n\u001b[1;32m    484\u001b[0m         model\u001b[39m=\u001b[39;49mmodel \u001b[39mif\u001b[39;49;00m model \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-16k-0613\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    485\u001b[0m     )\n\u001b[1;32m    486\u001b[0m     \u001b[39mif\u001b[39;00m debug:\n\u001b[1;32m    487\u001b[0m         \u001b[39mprint\u001b[39m(mat_reponse)\n",
      "File \u001b[0;32m/pscratch/sd/c/cyrusyc/materiathena/materiathena/mp/agent.py:451\u001b[0m, in \u001b[0;36mMPLLM.material_response\u001b[0;34m(self, message, model)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    450\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\"\u001b[39m, e, \u001b[39m\"\u001b[39m\u001b[39mTrying again with gpt-4-32k.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 451\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    452\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4-32k\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m    454\u001b[0m         functions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaterial_functions,\n\u001b[1;32m    455\u001b[0m         function_call\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    456\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    457\u001b[0m         top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    458\u001b[0m     )\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/dev/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The model `gpt-4-32k` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4."
     ]
    }
   ],
   "source": [
    "from materiathena.mp.agent import MPLLM\n",
    "\n",
    "\n",
    "mpllm = MPLLM()\n",
    "\n",
    "print(\"MPLLM is ready to serve you!\")\n",
    "\n",
    "\n",
    "# user_input = input(\"Enter materials-related question: \")\n",
    "user_input = \"What is the bandgap of stable BaTiO3?\"\n",
    "user_input = \"What is the elastic tensor of NaCl?\"\n",
    "user_input = \"What is the bandgap of stable MgSe?\"\n",
    "user_input = \"Is YbCl3 magnetic or non-magnetic?\"\n",
    "# user_input = \"What is the energy above hull of Cu3P4Pb3O16 at 0K?\"\n",
    "# user_input = \"Is Cu stable in FCC or BCC structure at 0K based on the energy distance above hull?\"\n",
    "# user_input = \"Do we have stable Cu-substituted lead phosphate apatite at 0K?\"\n",
    "# user_input = \"What is the bandgap of the most stable magnetite?\"\n",
    "# user_input = \"Search for the necessary information for FCC Cu and summarize for me.\"\n",
    "\n",
    "mpllm.run_material_conversation(user_input=user_input, debug=True)\n",
    "# mpllm.run_material_conversation(user_input, model=\"gpt-3.5-turbo-16k-0613\", debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198fa7f",
   "metadata": {},
   "source": [
    "# Hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openapi_schema_pydantic import PathItem, Operation, Parameter\n",
    "\n",
    "# class MPAPISpec:\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             force_download: bool = False,\n",
    "#             ):\n",
    "\n",
    "#         if force_download:\n",
    "#             spec = OpenAPISpec.from_url(\"https://api.materialsproject.org/openapi.json\")\n",
    "#             spec.\n",
    "\n",
    "# TODO: construct MPAPISpec class from OpenAPISpec\n",
    "\n",
    "\n",
    "def get_endpoints(spec: OpenAPISpec):\n",
    "    endpoints = [\n",
    "        (route, method, operation)\n",
    "        for route, paths in spec.paths.items()\n",
    "        for method, operation in paths\n",
    "        if method in [\"get\", \"post\"]\n",
    "    ]\n",
    "    return endpoints\n",
    "\n",
    "\n",
    "def get_functions(spec: OpenAPISpec):\n",
    "    endpoints = get_endpoints(spec)\n",
    "    functions = []\n",
    "    for route, method, operation in endpoints:\n",
    "        if operation is None:\n",
    "            continue\n",
    "\n",
    "        name = (\n",
    "            operation.operationId\n",
    "            if len(operation.operationId) <= 64\n",
    "            else operation.operationId[:64]\n",
    "        )\n",
    "\n",
    "        description = operation.description or operation.summary\n",
    "\n",
    "        properties = {\n",
    "            property.name: {\n",
    "                \"type\": property.param_schema.type,\n",
    "                \"description\": property.description\n",
    "                if property.description is not None\n",
    "                else \"\",\n",
    "                **(\n",
    "                    {\"enum\": property.param_schema.enum}\n",
    "                    if property.param_schema.enum is not None\n",
    "                    else {}\n",
    "                ),\n",
    "            }\n",
    "            for property in operation.parameters\n",
    "            if property.param_schema.type is not None\n",
    "        }\n",
    "\n",
    "        required = [\n",
    "            property.name for property in operation.parameters if property.required\n",
    "        ]\n",
    "        functions.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"description\": description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties,\n",
    "                },\n",
    "                **({\"required\": required} if required else {}),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return functions\n",
    "\n",
    "\n",
    "functions = get_functions(spec)\n",
    "\n",
    "print(len(functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"passed_functions.json\", \"w\") as f:\n",
    "#     json.dump(functions, f, indent=4)\n",
    "\n",
    "# functions\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"select_functions.json\", \"r\") as f:\n",
    "    functions = json.load(f)\n",
    "\n",
    "len(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e84068-df15-4050-9e9d-ccea43f82079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# import openai\n",
    "# from dotenv import load_dotenv\n",
    "# from mp_api.client import MPRester\n",
    "\n",
    "# from langchain.tools import APIOperation, OpenAPISpec\n",
    "\n",
    "# load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "# MP_API_KEY = os.getenv(\"MP_API_KEY\", None)\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# spec = OpenAPISpec.from_url(\"https://api.materialsproject.org/openapi.json\")\n",
    "# operation = APIOperation.from_openapi_spec(\n",
    "#     spec, \"/materials/summary/{material_id}/\", \"get\"\n",
    "# )\n",
    "\n",
    "# # from langchain.chat_models import ChatOpenAI, ChatAnthropic\n",
    "# # from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "# # from langchain.tools import format_tool_to_openai_function\n",
    "\n",
    "# # llm = ChatAnthropic(anthropic_api_key=)\n",
    "# # llm = ChatOpenAI(model='gpt-4-0613', temperature=0.5, openai_api_key=OPENAI_API_KEY, client=)\n",
    "\n",
    "\n",
    "# class LLMaterialsAgent:\n",
    "#     def __init__(self, mp_api_key=MP_API_KEY, openai_api_key=OPENAI_API_KEY):\n",
    "#         # Initialize the Materials Project API\n",
    "#         self.mpr = MPRester(mp_api_key)\n",
    "#         # Initialize the OpenAI API\n",
    "#         openai.api_key = openai_api_key\n",
    "\n",
    "#     def get_materials_data(self, query_params):\n",
    "#         # Retrieve data from the Materials Project using the MPRester class\n",
    "#         data = self.mpr.summary.search(**query_params)\n",
    "#         return data\n",
    "\n",
    "#     def run_conversation(self, user_input):\n",
    "#         # Step 1: send the conversation and available functions to GPT\n",
    "#         messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "#         functions = [\n",
    "#             {\n",
    "#                 \"name\": \"get_materials_data\",\n",
    "#                 \"description\": \"Get materials data from the Materials Project\",\n",
    "#                 \"parameters\": {\n",
    "#                     \"type\": \"object\",\n",
    "#                     \"properties\": {\n",
    "#                         \"elements\": {\n",
    "#                             \"type\": \"array\",\n",
    "#                             \"items\": {\"type\": \"string\"},\n",
    "#                             \"description\": \"Elements to query, e.g., ['Si', 'O']\",\n",
    "#                         },\n",
    "#                         \"band_gap\": {\n",
    "#                             \"type\": \"array\",\n",
    "#                             \"items\": {\"type\": \"number\"},\n",
    "#                             \"description\": \"Range of band gap values, e.g., [0.5, 1.0]\",\n",
    "#                         },\n",
    "#                         \"fields\": {\n",
    "#                             \"type\": \"array\",\n",
    "#                             \"items\": {\"type\": \"string\"},\n",
    "#                             \"description\": f\"Fields to return, including {self.mpr.summary.available_fields}\",\n",
    "#                         }\n",
    "#                         # \"limit\": {\n",
    "#                         #     \"type\": \"integer\",\n",
    "#                         #     \"description\": \"Number of materials to retrieve, e.g., 5\",\n",
    "#                         # },\n",
    "#                     },\n",
    "#                     \"required\": [\"elements\", \"band_gap\"],\n",
    "#                 },\n",
    "#             }\n",
    "#         ]\n",
    "#         response = openai.ChatCompletion.create(\n",
    "#             model=\"gpt-3.5-turbo-0613\",\n",
    "#             messages=messages,\n",
    "#             functions=functions,\n",
    "#             function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "#         )\n",
    "#         response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "#         # Step 2: check if GPT wanted to call a function\n",
    "#         if response_message.get(\"function_call\"):\n",
    "#             # Step 3: call the function\n",
    "#             # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "#             available_functions = {\n",
    "#                 \"get_materials_data\": self.get_materials_data,\n",
    "#             }  # only one function in this example, but you can have multiple\n",
    "#             function_name = response_message[\"function_call\"][\"name\"]\n",
    "#             function_to_call = available_functions[function_name]\n",
    "#             function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "#             function_response = function_to_call(query_params=function_args)\n",
    "\n",
    "#             # breakpoint()\n",
    "\n",
    "#             # Step 4: send the info on the function call and function response to GPT\n",
    "#             messages.append(\n",
    "#                 response_message\n",
    "#             )  # extend conversation with assistant's reply\n",
    "#             # breakpoint()\n",
    "#             messages.append(\n",
    "#                 {\n",
    "#                     \"role\": \"function\",\n",
    "#                     \"name\": function_name,\n",
    "#                     \"content\": json.dumps(function_response[0]),\n",
    "#                     # \"content\": function_response,\n",
    "#                 }\n",
    "#             )  # extend conversation with function response\n",
    "#             # breakpoint()\n",
    "#             second_response = openai.ChatCompletion.create(\n",
    "#                 model=\"gpt-3.5-turbo-0613\",\n",
    "#                 messages=messages,\n",
    "#             )  # get a new response from GPT where it can see the function response\n",
    "#             # breakpoint()\n",
    "#             return second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427454eb-7708-41ff-8b47-0607d836bd42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# user_input = input(\"Please enter your natural language query: \")\n",
    "\n",
    "# user_input = \"Is UCl3 a stable material according to the thermodynamic hull on Materials Project?\"\n",
    "\n",
    "user_input = \"What is the bandgap of diamond based on Materials Project's data?\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a data-vigilent agent that responds user requrests based on data hosted on Materials Project.\"\n",
    "            \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous. Only use the functions you have been provided with.\"\n",
    "            \"Remember to provide `fields` or `_fields` to retrive as small request as possible.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": user_input},\n",
    "]\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    # model=\"gpt-3.5-turbo-0613\",\n",
    "    model=\"gpt-3.5-turbo-16k-0613\",\n",
    "    # model=\"gpt-4-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae61be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# passed_functions = []\n",
    "# for n in tqdm(range(len(functions))):\n",
    "#     try:\n",
    "#         response = openai.ChatCompletion.create(\n",
    "#             model=\"gpt-3.5-turbo-0613\",\n",
    "#             messages=messages,\n",
    "#             functions=[functions[n]],\n",
    "#             function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "#         )\n",
    "#         response_message = response[\"choices\"][0][\"message\"]\n",
    "#     except Exception as e:\n",
    "#         print(functions[n][\"name\"])\n",
    "#         continue\n",
    "#     passed_functions.append(functions[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf11272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(map(lambda x: x['name'], functions)).index('search_materials_synthesis__get')\n",
    "\n",
    "# functions.pop(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86962426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"passed_functions.json\", \"w\") as f:\n",
    "#     json.dump(functions, f, indent=4)\n",
    "\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x[\"name\"], functions)).index(\"search_materials_summary__get\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b2407",
   "metadata": {},
   "source": [
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mp_api.client.core import BaseRester\n",
    "from mp_api.client.routes import *\n",
    "\n",
    "\n",
    "class MPLLM:\n",
    "    def __init__(self, mp_api_key=MP_API_KEY, openai_api_key=OPENAI_API_KEY) -> None:\n",
    "        openai.api_key = openai_api_key\n",
    "\n",
    "        self.base = BaseRester(\n",
    "            api_key=mp_api_key, monty_decode=True, use_document_model=False\n",
    "        )\n",
    "\n",
    "        self.materials = MaterialsRester(\n",
    "            api_key=mp_api_key, monty_decode=False, use_document_model=False\n",
    "        )\n",
    "\n",
    "        self.thermo = ThermoRester(\n",
    "            api_key=mp_api_key, monty_decode=False, use_document_model=False\n",
    "        )\n",
    "\n",
    "        self.tasks = TaskRester(\n",
    "            api_key=mp_api_key,\n",
    "        )\n",
    "\n",
    "        self.summary = SummaryRester(\n",
    "            api_key=mp_api_key, monty_decode=False, use_document_model=False\n",
    "        )\n",
    "\n",
    "    def search_base(self, query_params):\n",
    "        query_params[\"fields\"] = query_params.get(\"fields\", \"\").split(\",\")\n",
    "        _fields = query_params.pop(\"_fields\", None)\n",
    "        if _fields:\n",
    "            query_params[\"fields\"] += _fields.split(\",\")\n",
    "        return self.base._search(all_fields=False, **query_params)\n",
    "\n",
    "    def search_materials_core(self, query_params: dict):\n",
    "        query_params[\"fields\"] = query_params.get(\"fields\", \"\").split(\",\")\n",
    "        _fields = query_params.pop(\"_fields\", None)\n",
    "        if _fields:\n",
    "            query_params[\"fields\"] += _fields.split(\",\")\n",
    "        return self.materials._search(all_fields=False, **query_params)\n",
    "\n",
    "    def search_materials_summary(self, query_params: dict):\n",
    "        query_params[\"fields\"] = query_params.get(\"fields\", \"\").split(\",\")\n",
    "        _fields = query_params.pop(\"_fields\", None)\n",
    "        if _fields:\n",
    "            query_params[\"fields\"] += _fields.split(\",\")\n",
    "        return self.summary._search(all_fields=False, **query_params)\n",
    "\n",
    "    def search_materials_thermo(self, query_params):\n",
    "        query_params[\"fields\"] = query_params.get(\"fields\", \"\").split(\",\")\n",
    "        _fields = query_params.pop(\"_fields\", None)\n",
    "        if _fields:\n",
    "            query_params[\"fields\"] += _fields.split(\",\")\n",
    "        return self.thermo._search(all_fields=False, **query_params)\n",
    "\n",
    "\n",
    "mpllm = MPLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4c6ba-15f2-434c-8c3a-59c6b1cb5660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"search_base\": mpllm.search_base,\n",
    "    \"search_materials_thermo__get\": mpllm.search_materials_thermo,\n",
    "    \"search_materials_core__get\": mpllm.search_materials_core,\n",
    "    \"search_materials_summary_stats__get\": mpllm.search_materials_core,\n",
    "    \"search_materials_summary__get\": mpllm.search_materials_summary,\n",
    "}  # only one function in this example, but you can have multiple\n",
    "function_name = response_message[\"function_call\"][\"name\"]\n",
    "function_to_call = available_functions[function_name]\n",
    "function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "function_response = function_to_call(query_params=function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(function_to_call)\n",
    "print(function_args)\n",
    "\n",
    "response_message[\"function_call\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monty.json import MontyEncoder, MontyDecoder\n",
    "\n",
    "# json.dumps(function_response[0], cls=MontyEncoder)\n",
    "# json.dumps(function_response[0].dict(), indent=4, cls=MontyDecoder)\n",
    "# function_response[0]\n",
    "# MontyEncoder().encode(function_response[0])\n",
    "# MontyDecoder().decode(function_response[0].__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e88f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7264c-6a2e-4461-b069-831d85480c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = json.dumps(function_response)\n",
    "\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": content,\n",
    "        # \"content\": function_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16860c9b-d7bb-4009-a048-973744d4765d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")  # get a new response from GPT where it can see the function response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214ab19-0304-489d-b5ed-b948cb87d444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymatgen.core import Structure, Element\n",
    "import datetime\n",
    "\n",
    "\n",
    "def serialize_nested_object(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        serialized_dict = {}\n",
    "        for key, value in obj.items():\n",
    "            serialized_dict[key] = serialize_nested_object(value)\n",
    "        return serialized_dict\n",
    "    elif isinstance(obj, list):\n",
    "        serialized_list = []\n",
    "        for item in obj:\n",
    "            serialized_list.append(serialize_nested_object(item))\n",
    "        return serialized_list\n",
    "    elif isinstance(obj, (datetime.datetime, Element)):\n",
    "        return str(obj)\n",
    "    elif isinstance(obj, (str, int, float)):\n",
    "        return obj\n",
    "    else:\n",
    "        # Handle other data types or custom objects as needed\n",
    "        return str(obj)\n",
    "\n",
    "\n",
    "serialize_nested_object(function_response[0].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467a881-d1f7-443e-be86-bd123fd65740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monty.json import MontyEncoder\n",
    "\n",
    "encoder = MontyEncoder()\n",
    "a = encoder.encode(function_response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf2dbc-d1e4-4f38-a690-78052d904c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monty.json import MontyDecoder, MontyEncoder\n",
    "\n",
    "decoder = MontyDecoder()\n",
    "decoder.decode(function_response[0].dict())\n",
    "# encoder = MontyEncoder()\n",
    "# encoder.encode()\n",
    "# json.dumps(function_response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053d321-0599-4f20-9ffa-e0464ec4f3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
