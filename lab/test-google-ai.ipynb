{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyrus/dev/llamp/api/src/llamp/mp/tools.py:231: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"useful when you need dielectric properties like dielectric constant,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'phonopy'\n",
      "No module named 'phonopy'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents.initialize import initialize_agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "\n",
    "from llamp.mp.agents import (\n",
    "    MPSummaryExpert,\n",
    "    MPThermoExpert,\n",
    "    MPElasticityExpert,\n",
    "    MPDielectricExpert,\n",
    "    MPPiezoelectricExpert,\n",
    "    MPMagnetismExpert,\n",
    "    MPElectronicExpert,\n",
    "    MPSynthesisExpert,\n",
    "    MPStructureRetriever,\n",
    ")\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\", None)\n",
    "\n",
    "OPENAI_GPT_MODEL = \"gpt-4-1106-preview\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-4-0125-preview\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-3.5-turbo-1106\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-4\"\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_llm = GoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"models/gemini-pro\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    # streaming=True,\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "bottom_callback_handler = StreamingStdOutCallbackHandler()\n",
    "\n",
    "bottom_llm = GoogleGenerativeAI(\n",
    "    temperature=0.7,\n",
    "    model=\"models/gemini-pro\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    max_retries=5,\n",
    "    # streaming=True,\n",
    "    # callbacks=[bottom_callback_handler],\n",
    ")\n",
    "\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())\n",
    "\n",
    "tools = load_tools([\"llm-math\"], llm=bottom_llm)\n",
    "tools += [PythonREPLTool()]\n",
    "tools += [\n",
    "    MPThermoExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPElasticityExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPDielectricExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPMagnetismExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPElectronicExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPPiezoelectricExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPSummaryExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPSynthesisExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPStructureRetriever(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    # ArxivAgent(llm=bottom_llm).as_tool(agent_kwargs=dict(return_intermediate_steps=False)),\n",
    "    arxiv,\n",
    "    wikipedia,\n",
    "]\n",
    "\n",
    "instructions = re.sub(\n",
    "        r\"\\s+\",\n",
    "        \" \",\n",
    "        \"\"\"You are a data-aware agent that can consult materials-related\n",
    "    data through Materials Project (MP) database, arXiv, Wikipedia, and a python \n",
    "    REPL, which you can use to execute python code. If you get an error, debug \n",
    "    your code and try again. Only use the output of your code to answer the \n",
    "    question. Ask user to clarify their queries if needed. Please note that you \n",
    "    don't have direct control over MP but through multiple assistant agents to \n",
    "    help you. You need to provide complete context in the input for assistants to \n",
    "    do their job.\n",
    "    \"\"\",\n",
    "    ).replace(\"\\n\", \" \")\n",
    "base_prompt = hub.pull(\"langchain-ai/react-agent-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=5, return_messages=True\n",
    ")\n",
    "\n",
    "agent = create_react_agent(top_llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    memory=conversational_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: MPSummaryExpert\n",
      "Action Input: Get summary info for material NaCl\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"search_materials_summary__get\",\n",
      "  \"action_input\": {\n",
      "    \"formula\": \"NaCl\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mError on search_materials_summary__get: `fields` must be specified in the query. Please provide more detailed reqeust arguments or try smaller request by specifying 'limit' in request.\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Please provide more detailed reqeust arguments or try smaller request by specifying 'limit' in request.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m{'input': 'Get summary info for material NaCl', 'output': \"Please provide more detailed reqeust arguments or try smaller request by specifying 'limit' in request.\"}\u001b[0m\u001b[32;1m\u001b[1;3m Do I need to use a tool? Yes\n",
      "Action: MPStructureRetriever\n",
      "Action Input: Get structure for stable NaCl\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"search_materials_summary__get\",\n",
      "  \"action_input\": {\n",
      "    \"formula\": \"NaCl\",\n",
      "    \"is_stable\": true\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mError on search_materials_summary__get: `fields` must be specified in the query. Please provide more detailed reqeust arguments or try smaller request by specifying 'limit' in request.\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm sorry, I can't get structure for that material using the provided materials database. Please try again with a different material name.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{'input': 'Get structure for stable NaCl', 'output': \"I'm sorry, I can't get structure for that material using the provided materials database. Please try again with a different material name.\"}\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "Final Answer: I do not have access to the data requested.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Please give me the mass density (in g/cm^3) and volume per atom (in Angstrom^3) of stable NaCl.',\n",
       " 'chat_history': [],\n",
       " 'output': 'I do not have access to the data requested.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Please give me the mass density (in g/cm^3) and volume per atom (in Angstrom^3) of stable NaCl.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Mass density:** 2.165 g/cm^3\\n\\n**Volume per atom:** 23.9 Angstrom^3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_gemini = GoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"models/gemini-pro\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    # streaming=True,\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "llm_gemini.invoke(agent_executor.memory.chat_memory.messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
