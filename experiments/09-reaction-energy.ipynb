{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents.initialize import initialize_agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# from langchain.schema import ChatMessage, SystemMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "\n",
    "from llamp.mp.agents import (\n",
    "    MPSummaryExpert,\n",
    "    MPThermoExpert,\n",
    "    MPElasticityExpert,\n",
    "    MPDielectricExpert,\n",
    "    MPPiezoelectricExpert,\n",
    "    MPMagnetismExpert,\n",
    "    MPElectronicExpert,\n",
    "    MPSynthesisExpert,\n",
    "    MPStructureRetriever,\n",
    ")\n",
    "# from llamp.arxiv.agents import ArxivAgent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\", None)\n",
    "\n",
    "OPENAI_GPT_MODEL = \"gpt-4-1106-preview\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-4-0125-preview\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-3.5-turbo-1106\"\n",
    "# OPENAI_GPT_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=OPENAI_GPT_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_organization=OPENAI_ORGANIZATION,\n",
    "    streaming=False,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "bottom_callback_handler = StreamingStdOutCallbackHandler()\n",
    "\n",
    "bottom_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=OPENAI_GPT_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_organization=OPENAI_ORGANIZATION,\n",
    "    max_retries=5,\n",
    "    streaming=True,\n",
    "    callbacks=[bottom_callback_handler],\n",
    ")\n",
    "\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())\n",
    "\n",
    "tools = load_tools([\"llm-math\"], llm=bottom_llm)\n",
    "tools += [PythonREPLTool()]\n",
    "tools += [\n",
    "    MPThermoExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPElasticityExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPDielectricExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPMagnetismExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPElectronicExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPPiezoelectricExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPSummaryExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPSynthesisExpert(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    MPStructureRetriever(llm=bottom_llm).as_tool(\n",
    "        agent_kwargs=dict(return_intermediate_steps=False)\n",
    "    ),\n",
    "    # ArxivAgent(llm=bottom_llm).as_tool(agent_kwargs=dict(return_intermediate_steps=False)),\n",
    "    arxiv,\n",
    "    wikipedia,\n",
    "]\n",
    "\n",
    "instructions = re.sub(\n",
    "        r\"\\s+\",\n",
    "        \" \",\n",
    "        \"\"\"You are a data-aware agent that can consult materials-related\n",
    "    data through Materials Project (MP) database, arXiv, Wikipedia, and a python \n",
    "    REPL, which you can use to execute python code. If you get an error, debug \n",
    "    your code and try again. Only use the output of your code to answer the \n",
    "    question. Ask user to clarify their queries if needed. Please note that you \n",
    "    don't have direct control over MP but through multiple assistant agents to \n",
    "    help you. You need to provide complete context in the input for assistants to \n",
    "    do their job.\n",
    "    \"\"\",\n",
    "    ).replace(\"\\n\", \" \") #TODO: better way to call the llm\n",
    "base_prompt = hub.pull(\"langchain-ai/react-agent-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=5, return_messages=True\n",
    ") # TODO: can disable\n",
    "\n",
    "agent = create_react_agent(top_llm, tools, prompt) # TODO: update agent\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    memory=conversational_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"\"\"Recommand the synthesis recipe for BaTiO3 and calculate the reaction enthalpy for each step.\"\"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.memory.chat_memory.messages[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
